{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd83d575",
   "metadata": {},
   "source": [
    "# Cell 1 – Imports & paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c96ea00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import Video\n",
    "\n",
    "SEQ = \"seq_02\"\n",
    "\n",
    "# Base directory for your sequence 1 data\n",
    "BASE_DIR = f\"34759_final_project_rect/{SEQ}\"\n",
    "\n",
    "LEFT_DIR  = os.path.join(BASE_DIR, \"image_02\", \"data\")  # left images\n",
    "RIGHT_DIR = os.path.join(BASE_DIR, \"image_03\", \"data\")  # right images\n",
    "LABELS_TXT = os.path.join(BASE_DIR, \"labels.txt\")\n",
    "\n",
    "print(\"Left images dir :\", LEFT_DIR)\n",
    "print(\"Right images dir:\", RIGHT_DIR)\n",
    "print(\"Labels file     :\", LABELS_TXT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667e106a",
   "metadata": {},
   "source": [
    "# Cell 2 – Load labels into a dict: frame_id -> list of objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd268145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: parse labels.txt into a dictionary\n",
    "\n",
    "def load_labels(labels_path):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        dict: frame_id (int) -> list of dicts with keys:\n",
    "              'track_id', 'type', 'truncated', 'occluded', 'alpha',\n",
    "              'bbox', 'dimensions', 'location', 'rotation_y'\n",
    "    \"\"\"\n",
    "    annotations = defaultdict(list)\n",
    "\n",
    "    with open(labels_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            parts = line.split()\n",
    "            # According to description:\n",
    "            # frame, track_id, type, truncated, occluded, alpha,\n",
    "            # bbox_l, bbox_t, bbox_r, bbox_b,\n",
    "            # h, w, l,\n",
    "            # x, y, z,\n",
    "            # rotation_y,\n",
    "            # [optional score]\n",
    "\n",
    "            frame      = int(parts[0])\n",
    "            track_id   = int(parts[1])\n",
    "            obj_type   = parts[2]\n",
    "            truncated  = float(parts[3])\n",
    "            occluded   = int(parts[4])\n",
    "            alpha      = float(parts[5])\n",
    "\n",
    "            bbox = list(map(float, parts[6:10]))          # [l, t, r, b]\n",
    "            dims = list(map(float, parts[10:13]))         # [h, w, l]\n",
    "            loc  = list(map(float, parts[13:16]))         # [x, y, z]\n",
    "            rotation_y = float(parts[16])\n",
    "\n",
    "            ann = {\n",
    "                \"track_id\": track_id,\n",
    "                \"type\": obj_type,\n",
    "                \"truncated\": truncated,\n",
    "                \"occluded\": occluded,\n",
    "                \"alpha\": alpha,\n",
    "                \"bbox\": bbox,\n",
    "                \"dimensions\": dims,\n",
    "                \"location\": loc,\n",
    "                \"rotation_y\": rotation_y,\n",
    "            }\n",
    "\n",
    "            # If score is present (for detections) you could also store it:\n",
    "            if len(parts) > 17:\n",
    "                ann[\"score\"] = float(parts[17])\n",
    "            \n",
    "            if occluded > 0:\n",
    "                annotations[frame].append(ann)\n",
    "\n",
    "    return annotations\n",
    "\n",
    "annotations_by_frame = load_labels(LABELS_TXT)\n",
    "print(f\"Loaded annotations for {len(annotations_by_frame)} frames.\")\n",
    "print(\"Example frame ids:\", list(sorted(annotations_by_frame.keys()))[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4270bc72",
   "metadata": {},
   "source": [
    "# Cell 3 – List & index images by frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c07dcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: load sorted list of left and right images\n",
    "\n",
    "def sorted_image_paths(img_dir):\n",
    "    files = [f for f in os.listdir(img_dir) if f.lower().endswith(\".png\")]\n",
    "    files = sorted(files)\n",
    "    return [os.path.join(img_dir, f) for f in files]\n",
    "\n",
    "left_image_paths  = sorted_image_paths(LEFT_DIR)\n",
    "right_image_paths = sorted_image_paths(RIGHT_DIR)\n",
    "\n",
    "num_frames = min(len(left_image_paths), len(right_image_paths))\n",
    "print(f\"Found {num_frames} frames.\")\n",
    "\n",
    "# Simple helper: get image for a given frame id\n",
    "def load_frame_images(frame_id):\n",
    "    if frame_id < 0 or frame_id >= num_frames:\n",
    "        raise IndexError(f\"Frame id {frame_id} out of range (0..{num_frames-1})\")\n",
    "\n",
    "    left_img  = cv2.imread(left_image_paths[frame_id])\n",
    "    right_img = cv2.imread(right_image_paths[frame_id])\n",
    "    return left_img, right_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fd8c42",
   "metadata": {},
   "source": [
    "# Cell 4 – Drawing helper (bounding boxes, labels, coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7b92a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: function to overlay annotations on an image\n",
    "\n",
    "def draw_annotations(image, annotations):\n",
    "    \"\"\"\n",
    "    Draws bounding boxes, labels, and 3D coordinates on a copy of `image`.\n",
    "    Returns the annotated image (BGR).\n",
    "    \"\"\"\n",
    "    img = image.copy()\n",
    "\n",
    "    for ann in annotations:\n",
    "        l, t, r, b = ann[\"bbox\"]\n",
    "        obj_type = ann[\"type\"]\n",
    "        track_id = ann[\"track_id\"]\n",
    "        x, y, z = ann[\"location\"]\n",
    "\n",
    "        # Convert to int pixel coords\n",
    "        pt1 = (int(l), int(t))\n",
    "        pt2 = (int(r), int(b))\n",
    "\n",
    "        # Box\n",
    "        cv2.rectangle(img, pt1, pt2, (0, 255, 0), 2)\n",
    "\n",
    "        # First line: class + id\n",
    "        label_1 = f\"{obj_type} #{track_id}\"\n",
    "        # Second line: x,z (you can include y as well)\n",
    "        label_2 = f\"x={x:.1f}m, y={y:.1f}m, z={z:.1f}m\"\n",
    "\n",
    "        # Put text slightly above box\n",
    "        y0 = max(int(t) - 25, 0)\n",
    "        cv2.putText(img, label_1, (int(l), y0),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        y1 = max(int(t) - 5, 0)\n",
    "        cv2.putText(img, label_2, (int(l), y1),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fb8b61",
   "metadata": {},
   "source": [
    "# Cell 5 – Show a few sample frames with overlays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df790280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: visualize some sample frames with bounding boxes\n",
    "\n",
    "sample_frames = sorted(list(annotations_by_frame.keys()))[:3]  # first 3 frames with objects\n",
    "\n",
    "plt.figure(figsize=(15, 5 * len(sample_frames)))\n",
    "\n",
    "for i, frame_id in enumerate(sample_frames):\n",
    "    left_img, _ = load_frame_images(frame_id)\n",
    "    anns = annotations_by_frame.get(frame_id, [])\n",
    "\n",
    "    left_img_annotated = draw_annotations(left_img, anns)\n",
    "    # Convert BGR -> RGB for matplotlib\n",
    "    left_rgb = cv2.cvtColor(left_img_annotated, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    plt.subplot(len(sample_frames), 1, i + 1)\n",
    "    plt.imshow(left_rgb)\n",
    "    plt.title(f\"Frame {frame_id} with {len(anns)} objects\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5da1a2",
   "metadata": {},
   "source": [
    "# Cell 6 – Create a video with all frames + overlays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35811972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: create a video with annotations over all frames\n",
    "\n",
    "output_video_path = os.path.join(f\"{SEQ}_annotated.mp4\")\n",
    "fps = 10  # change if you like\n",
    "\n",
    "# Read the first frame to get size\n",
    "first_left, _ = load_frame_images(0)\n",
    "height, width = first_left.shape[:2]\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "video_writer = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "for frame_id in range(num_frames):\n",
    "    left_img, _ = load_frame_images(frame_id)\n",
    "    anns = annotations_by_frame.get(frame_id, [])\n",
    "    frame_annotated = draw_annotations(left_img, anns)\n",
    "    video_writer.write(frame_annotated)\n",
    "\n",
    "video_writer.release()\n",
    "print(\"Saved video to:\", output_video_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
